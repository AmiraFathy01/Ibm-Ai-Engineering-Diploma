{"cells":[{"cell_type":"markdown","id":"68b353df-284d-4644-99c5-e9e72a5b1bdd","metadata":{},"outputs":[],"source":["\u003ca href=\"https://cognitiveclass.ai/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\"\u003e\u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/image/IDSN-logo.png\" width=\"400\"\u003e \u003c/a\u003e\n","\n","\u003ch1 align=center\u003e\u003cfont size = 5\u003eData Preparation\u003c/font\u003e\u003c/h1\u003e\n"]},{"cell_type":"markdown","id":"17b45781-bc60-4628-96f4-4908a5f57b05","metadata":{},"outputs":[],"source":["## Objective\n"]},{"cell_type":"markdown","id":"d7a2ee6b-9dbe-4fd2-a45d-44659b65389b","metadata":{},"outputs":[],"source":["In this lab, you will learn how to load images and manipulate them for training using Keras ImageDataGenerator.\n"]},{"cell_type":"markdown","id":"8f1c804d-7c7d-437a-8581-a0a341dd479b","metadata":{},"outputs":[],"source":["## Table of Contents\n","\n","\u003cdiv class=\"alert alert-block alert-info\" style=\"margin-top: 20px\"\u003e\n","\n","\u003cfont size = 3\u003e    \n","\n","1. \u003ca href=\"#item22\"\u003eImport Libraries and Packages\u003c/a\u003e \n","2. \u003ca href=\"#item21\"\u003eDownload Data\u003c/a\u003e \n","3. \u003ca href=\"#item23\"\u003eConstruct an ImageDataGenerator Instance\u003c/a\u003e  \n","4. \u003ca href=\"#item24\"\u003eVisualize Batches of Images\u003c/a\u003e\n","5. \u003ca href=\"#item25\"\u003eQuestions\u003c/a\u003e    \n","\u003c/font\u003e\n","    \n","\u003c/div\u003e\n"]},{"cell_type":"markdown","id":"a2308959-403d-48a6-9cab-0cedd37cfa45","metadata":{},"outputs":[],"source":["   \n"]},{"cell_type":"markdown","id":"3a888418-b4cc-456d-bbef-07fa9d107c73","metadata":{},"outputs":[],"source":["\u003ca id=\"item1\"\u003e\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"79ee144c-eb65-449c-8cae-73f261ef5ca9","metadata":{},"outputs":[],"source":["\u003ca id='item21'\u003e\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"800ae295-fd58-4a1f-b296-ea132082fd55","metadata":{},"outputs":[],"source":["## Import Libraries and Packages\n"]},{"cell_type":"markdown","id":"1acb3501-c22f-46f3-8a81-80d85ccf163a","metadata":{},"outputs":[],"source":["Before we proceed, let's import the libraries and packages that we will need to complete the rest of this lab.\n"]},{"cell_type":"code","id":"227c04b5-3a15-43a3-9eed-f937c18e57e0","metadata":{},"outputs":[],"source":["import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport skillsnetwork\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"markdown","id":"a95ed338-8e4b-4e0e-8b9d-98adec29a94f","metadata":{},"outputs":[],"source":["## Download Data\n"]},{"cell_type":"markdown","id":"2f7a808f-17c2-416c-aded-356a74d908c9","metadata":{},"outputs":[],"source":["For your convenience, I have placed the data on a server which you can retrieve and unzip easily using the **skillsnetwork.prepare** command. So let's run the following line of code to get the data. Given the large size of the image dataset, it might take some time depending on your internet speed.\n"]},{"cell_type":"code","id":"54fecc67-a57d-4ed4-ace2-7c0982750513","metadata":{},"outputs":[],"source":["await skillsnetwork.prepare(\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week2.zip\",path = \"./\", overwrite=True)"]},{"cell_type":"markdown","id":"ad70e217-6168-4b27-846b-61cbf55a1100","metadata":{},"outputs":[],"source":["Now, you should see two folders appear in the left pane: *Positive* and *Negative*. *Negative* is the negative class like we defined it earlier and it represents the concrete images with no cracks. *Positive* on the other hand is the positive class and represents the concrete images with cracks.\n"]},{"cell_type":"markdown","id":"52375065-6589-4400-ac0b-d4bc1015a063","metadata":{},"outputs":[],"source":["**Important Note**: There are thousands and thousands of images in each folder, so please don't attempt to double click on the *Negative* and *Positive* folders. This may consume all of your memory and you may end up with a **50*** error. So please **DO NOT DO IT**.\n"]},{"cell_type":"markdown","id":"ba6f7420-86cd-45fa-854a-c62a5f4322f2","metadata":{},"outputs":[],"source":["You can check the content of \u003ccode\u003e./concrete_data_week2\u003c/code\u003e by running the following:\n"]},{"cell_type":"code","id":"2930bd1b-d11f-4dfd-a1eb-1097a3c8881d","metadata":{},"outputs":[],"source":["!ls ./concrete_data_week2"]},{"cell_type":"markdown","id":"08c719b1-9c25-41ae-b15e-bbb1835ec921","metadata":{},"outputs":[],"source":["or the following:\n"]},{"cell_type":"code","id":"1bfaab24-4829-429f-ae1a-8a09340171cc","metadata":{},"outputs":[],"source":["os.listdir('concrete_data_week2')"]},{"cell_type":"markdown","id":"2d69d897-18d4-4796-908e-ff83dc4ced25","metadata":{},"outputs":[],"source":["\u003ca id='item22'\u003e\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"d946ba63-43e3-4836-982e-54a35efad3d2","metadata":{},"outputs":[],"source":[" \n"]},{"cell_type":"markdown","id":"9cc8930d-5a0f-4afc-a1c8-2d816a997aa8","metadata":{},"outputs":[],"source":["\u003ca id='item23'\u003e\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"d151023d-8b8c-4a39-b67b-a6cb76fd1b57","metadata":{},"outputs":[],"source":["## Construct an ImageDataGenerator Instance\n"]},{"cell_type":"markdown","id":"7b2ee197-6fba-4d71-b0cb-3cc758bdf54e","metadata":{},"outputs":[],"source":["In this section, you will learn how to define a Keras ImageDataGenerator instance and use it to load and manipulate data for building a deep learning model.\n"]},{"cell_type":"markdown","id":"95ffb76a-c18a-4f4d-84bc-c1d0a174cd1b","metadata":{},"outputs":[],"source":["Before we proceed, let's define a variable that represents the path to the folder containing our data which is \u003ccode\u003econcrete_data_week2\u003c/code\u003e in this case.\n"]},{"cell_type":"code","id":"d2a3db7b-5227-45af-8809-c47abb8fe065","metadata":{},"outputs":[],"source":["dataset_dir = './concrete_data_week2'"]},{"cell_type":"markdown","id":"52e2b0e7-b152-499c-adcb-afc68a04b8ec","metadata":{},"outputs":[],"source":["Keras ImageDataGenerator requires images be arranged in a certain folder hierarchy, where the main directory would contain folders equal to the number of classes in your problem. Since in this case we are trying to build a classifier of two classes, then our main directory, which is \u003ccode\u003econcrete_data_week2\u003c/code\u003e, should contain two folders, one for each class. This has already been done for you as the negative images are in one folder and the positive images are in another folder.\n"]},{"cell_type":"markdown","id":"49ef1f1d-e437-4fd6-990d-2838cf6cb38b","metadata":{},"outputs":[],"source":["Let's go ahead and define an instance of the Keras ImageDataGenerator. \n"]},{"cell_type":"markdown","id":"a20af852-894e-4649-bac2-62c39d1af6cc","metadata":{},"outputs":[],"source":["#### Standard ImageDataGenerator\n"]},{"cell_type":"markdown","id":"281057b8-0aba-450b-918e-d3c7cad27c52","metadata":{},"outputs":[],"source":["You can define a standard one like this, where you are simply using the ImageDataGenerator to train your model in batches.\n"]},{"cell_type":"code","id":"93ea6fb1-37e0-43a3-aae1-cd4fd3223f50","metadata":{},"outputs":[],"source":["# instantiate your image data generator\ndata_generator = ImageDataGenerator()"]},{"cell_type":"markdown","id":"8a52be8a-e4f3-4d7c-a8c6-5ea665c8a98e","metadata":{},"outputs":[],"source":["Next, you use the \u003ccode\u003eflow_from_directory\u003c/code\u003e methods to loop through the images in batches. In this method, you pass the directory where the images reside, the size of each batch, *batch_size*, and since batches are sampled randomly, then you can also specify a random seed, *seed*, if you would like to reproduce the batch sampling. In case you would like to resize your images, then you can using the *target_size* argument to accomplish that.\n"]},{"cell_type":"code","id":"891f8612-ea69-42b4-80c7-6c4fd3d50f0e","metadata":{},"outputs":[],"source":["image_generator = data_generator.flow_from_directory(\n    dataset_dir,\n    batch_size=4,\n    class_mode='categorical',\n    seed=24\n    )"]},{"cell_type":"markdown","id":"c843d1e0-518b-464f-b7dd-23b58b398395","metadata":{},"outputs":[],"source":["What is great about this method, is it prints a summary of it found in the directory passed. Here, it found 40,000 images in total belonging to 2 classes.\n"]},{"cell_type":"markdown","id":"d68a83ec-dc5b-4456-89a0-a8b53d7713a4","metadata":{},"outputs":[],"source":["Now, to access the batches, you use the \u003ccode\u003enext\u003c/code\u003e method as follows:\n"]},{"cell_type":"code","id":"70218eab-0c3b-4860-9e46-2a389c4afcbb","metadata":{},"outputs":[],"source":["first_batch = image_generator.next()\nfirst_batch"]},{"cell_type":"markdown","id":"f73dbab9-c6ba-4749-9346-ddd7138e46d8","metadata":{},"outputs":[],"source":["As you can see, this returned the images along with their labels. Therefore, the following returns the images only,\n"]},{"cell_type":"code","id":"d4cdf262-2b01-47eb-9d8d-20fa5051aa38","metadata":{},"outputs":[],"source":["first_batch_images = image_generator.next()[0]\nfirst_batch_images"]},{"cell_type":"markdown","id":"b4dd2050-c90c-4ec4-bb77-e64fdd27d172","metadata":{},"outputs":[],"source":["and the following returns the labels only.\n"]},{"cell_type":"code","id":"ae21efd5-6e43-409d-8cad-e39851d65677","metadata":{},"outputs":[],"source":["first_batch_labels = image_generator.next()[1]\nfirst_batch_labels"]},{"cell_type":"markdown","id":"bb2fd3cf-3c60-4945-9a3b-ecd82a51dd31","metadata":{},"outputs":[],"source":["#### Custom ImageDataGenerator\n"]},{"cell_type":"markdown","id":"46eb6c18-667b-4fc7-97bb-d5ed582eb1e8","metadata":{},"outputs":[],"source":["You can also specify some transforms, like scaling, rotations, and flips, that you would like applied to the images when you define an ImageDataGenerator object. Say you want to normalize your images, then you can define your ImageDataGenerator instance as follows:\n"]},{"cell_type":"code","id":"9f200ff0-fd10-4d8e-833a-7c7df372ed8e","metadata":{},"outputs":[],"source":["# instantiate your image data generator\ndata_generator = ImageDataGenerator(\n    rescale=1./255\n)"]},{"cell_type":"markdown","id":"77f7f17a-7e0d-4af3-9edf-01044f383f97","metadata":{},"outputs":[],"source":["And then you proceed with defining your *image_generator* using the *flow_from_directory* method, just like before.\n"]},{"cell_type":"code","id":"32470637-90de-4f00-a2b9-90bfbbccf12a","metadata":{},"outputs":[],"source":["image_generator = data_generator.flow_from_directory(\n    dataset_dir,\n    batch_size=4,\n    class_mode='categorical',\n    seed=24\n    )"]},{"cell_type":"markdown","id":"9c5569fe-a759-4a15-908a-2c18e1239be2","metadata":{},"outputs":[],"source":["However, now we explore the first batch using the *next* method, \n"]},{"cell_type":"code","id":"5e2972d6-795b-4ccf-ac58-0b814748401f","metadata":{},"outputs":[],"source":["first_batch = image_generator.next()\nfirst_batch"]},{"cell_type":"markdown","id":"9de30fec-38dc-4ed2-b48e-acbb7030b79d","metadata":{},"outputs":[],"source":["we find that the values are not integer values anymore, but scaled resolution since the original number are divided by 255.\n"]},{"cell_type":"markdown","id":"56c9cf4d-31e6-45df-8c58-2908d0c4ec16","metadata":{},"outputs":[],"source":["You can learn more about the Keras ImageDataGeneration class [here](https://keras.io/preprocessing/image/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01).\n"]},{"cell_type":"markdown","id":"56a71fed-bd67-4c6b-928e-88cc7b09a937","metadata":{},"outputs":[],"source":["\u003ca id='item24'\u003e\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"da2a0e2c-b392-4d87-93d4-08775eb25289","metadata":{},"outputs":[],"source":["## Visualize Batches of Images\n"]},{"cell_type":"markdown","id":"33f3ceee-be31-4f70-960f-c236ee2f51fa","metadata":{},"outputs":[],"source":["Let write some code to visualize a batch. We will use subplots in order to make visualizing the images easier.\n"]},{"cell_type":"markdown","id":"4a93334f-6c8c-4d3f-a61e-00a045df7ed2","metadata":{},"outputs":[],"source":["Recall that we can access our batch images as follows:\n","\n","\u003ccode\u003efirst_batch_images = image_generator.next()[0] # first batch\u003c/code\u003e\n","\n","\u003ccode\u003esecond_batch_images = image_generator.next()[0] # second batch\u003c/code\u003e\n","\n","and so on.\n"]},{"cell_type":"code","id":"3d2e7611-93aa-4981-8376-4d9a7bff2107","metadata":{},"outputs":[],"source":["fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(20, 10)) # define your figure and axes\n\nind = 0\nfor ax1 in axs:\n    for ax2 in ax1: \n        image_data = first_batch_images[ind].astype(np.uint8)\n        ax2.imshow(image_data)\n        ind += 1\n\nfig.suptitle('First Batch of Concrete Images') \nplt.show()"]},{"cell_type":"markdown","id":"80e59d5c-cfc8-43f4-bc75-151af7a34a79","metadata":{},"outputs":[],"source":["Remember that batches are sampled randomly from the data. In our first batch, we ended up with two negative image and two positive images.\n"]},{"cell_type":"markdown","id":"fabb28f9-b57e-403b-9966-40bf8cc1cb25","metadata":{},"outputs":[],"source":["**Important Note**: Because of a bug with the imshow function in Matplotlib, if you are plotting the unscaled RGB images, you have to cast the **image_data** to uint8 before you call the \u003ccode\u003eimshow\u003c/code\u003e function. So In the code above It looks like this:\n","\n","image_data = first_batch_images[ind].astype(np.uint8)\n"]},{"cell_type":"markdown","id":"3c3fefda-ee24-4f7a-bd7b-66624497b9eb","metadata":{},"outputs":[],"source":["\u003ca id='item25'\u003e\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"1ac5a669-f236-4947-b4ac-534592f9d735","metadata":{},"outputs":[],"source":["## Questions\n"]},{"cell_type":"markdown","id":"4ce21775-d6d9-4f53-b745-54d9257c59f5","metadata":{},"outputs":[],"source":["### Question: Create a plot to visualize the images in the third batch.\n"]},{"cell_type":"code","id":"afd6f9f2-d99e-4879-b03a-5e15d7bc81b9","metadata":{},"outputs":[],"source":["## You can use this cell to type your code to answer the above question\n\n\n\n"]},{"cell_type":"markdown","id":"3ef864e1-12b4-436c-8819-5fc777921c08","metadata":{},"outputs":[],"source":["### Question: How many images from each class are in the fourth batch?\n"]},{"cell_type":"code","id":"0e482ee9-0893-490c-93f2-72b8e7940459","metadata":{},"outputs":[],"source":["## You can use this cell to type your code to answer the above question\n\n\n"]},{"cell_type":"markdown","id":"751ee2ce-b248-4ecb-94dd-062920e9e998","metadata":{},"outputs":[],"source":["### Question: Create a plot to visualize the second image in the fifth batch.\n"]},{"cell_type":"code","id":"d61d6820-c636-4818-b43d-1843b21a3bd7","metadata":{},"outputs":[],"source":["## You can use this cell to type your code to answer the above question\n\n\n"]},{"cell_type":"markdown","id":"ad7fb399-7ab8-4bfa-af99-ee0a7182b850","metadata":{},"outputs":[],"source":["### Question: How many images from each class are in the fifth batch?\n"]},{"cell_type":"code","id":"25af244d-b5ed-422e-b267-a0fa103f7302","metadata":{},"outputs":[],"source":["## You can use this cell to type your code to answer the above question\n\n\n"]},{"cell_type":"markdown","id":"4de00977-4fa9-4394-8b7a-c391da4de059","metadata":{},"outputs":[],"source":["   \n"]},{"cell_type":"markdown","id":"90701f41-25cf-4b30-b060-dfc1c89a7b66","metadata":{},"outputs":[],"source":["Make sure to answer the above questions as the quiz in this module is heavily based on them.\n"]},{"cell_type":"markdown","id":"f361739c-fc61-4c3d-a49f-34875c73be5f","metadata":{},"outputs":[],"source":["  \n"]},{"cell_type":"markdown","id":"76bdcc4f-5d37-45d0-bf51-228de30cb011","metadata":{},"outputs":[],"source":["   \n"]},{"cell_type":"markdown","id":"49617b80-61be-4898-bbb9-0659328e26c2","metadata":{},"outputs":[],"source":["### Thank you for completing this lab!\n","\n","This notebook was created by Alex Aklson. I hope you found this lab interesting and educational.\n"]},{"cell_type":"markdown","id":"18b7ca60-ce23-48cb-8f24-43de6cfeab17","metadata":{},"outputs":[],"source":["This notebook is part of a course on **Coursera** called *AI Capstone Project with Deep Learning*. If you accessed this notebook outside the course, you can take this course online by clicking [here](https://cocl.us/DL0321EN_Coursera_Week2_LAB1).\n"]},{"cell_type":"markdown","id":"ebb86557-4728-42b3-93ae-1b27bf260875","metadata":{},"outputs":[],"source":["\n","## Change Log\n","\n","|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2020-09-18  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n","\n"]},{"cell_type":"markdown","id":"7a55c4df-49ac-492d-bb02-78ebbae73f8b","metadata":{},"outputs":[],"source":["\u003chr\u003e\n","\n","Copyright \u0026copy; 2020 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_medium=dswb\u0026utm_source=bducopyrightlink\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\u0026utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01).\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}