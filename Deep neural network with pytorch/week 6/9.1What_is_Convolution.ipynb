{"cells":[{"cell_type":"markdown","metadata":{},"source":["\u003cp style=\"text-align:center\"\u003e\n","    \u003ca href=\"https://skills.network/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0110ENSkillsNetwork952-2022-01-01\" target=\"_blank\"\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  /\u003e\n","    \u003c/a\u003e\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","\u003ch3\u003eObjective for this Notebook\u003ch3\u003e    \n","\u003ch5\u003e 1. Learn about Convolution.\u003c/h5\u003e\n","\u003ch5\u003e 2. Leran Determining  the Size of Output. \u003c/h5\u003e\n","\u003ch5\u003e 3. Learn Stride, Zero Padding\u003c/h5\u003e   \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","# Table of Contents\n","In this lab, you will study convolution and review how the different operations change the relationship between input and output.\n","\n","\u003cdiv class=\"alert alert-block alert-info\" style=\"margin-top: 20px\"\u003e\n","\u003cli\u003e\u003ca href=\"#ref0\"\u003eWhat is Convolution  \u003c/a\u003e\u003c/li\u003e\n","\n","\u003cli\u003e\u003ca href=\"#ref1\"\u003eDetermining  the Size of Output\u003c/a\u003e\u003c/li\u003e\n","\u003cli\u003e\u003ca href=\"#ref2\"\u003eStride\u003c/a\u003e\u003c/li\u003e\n","\u003cli\u003e\u003ca href=\"#ref3\"\u003eZero Padding \u003c/a\u003e\u003c/li\u003e\n","\u003cli\u003e\u003ca href=\"#ref4\"\u003ePractice Questions \u003c/a\u003e\u003c/li\u003e\n","\n","\u003cbr\u003e\n","\u003cp\u003e\u003c/p\u003e\n","Estimated Time Needed: \u003cstrong\u003e25 min\u003c/strong\u003e\n","\u003c/div\u003e\n","\n","\u003chr\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["Import the following libraries: \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch \n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from scipy import ndimage, misc"]},{"cell_type":"markdown","metadata":{},"source":["\u003ca id=\"ref0\"\u003e\u003c/a\u003e\n","\u003ch2 align=center\u003eWhat is Convolution?\u003c/h2\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["Convolution is a linear operation similar to a linear equation, dot product, or matrix multiplication. Convolution has several advantages for analyzing images. As discussed in the video, convolution preserves the relationship between elements, and it requires fewer parameters than other methods.  \n"]},{"cell_type":"markdown","metadata":{},"source":["You can see the relationship between the different methods that you learned:\n","\n","$$linear \\ equation :y=wx+b$$\n","$$linear\\ equation\\ with\\ multiple \\ variables \\ where \\ \\mathbf{x} \\ is \\ a \\ vector \\ \\mathbf{y}=\\mathbf{wx}+b$$\n","$$ \\ matrix\\ multiplication \\ where \\ \\mathbf{X} \\ in \\ a \\ matrix \\ \\mathbf{y}=\\mathbf{wX}+\\mathbf{b} $$\n","$$\\ convolution \\ where \\ \\mathbf{X} \\ and \\ \\mathbf{Y} \\ is \\ a \\ tensor \\  \\mathbf{Y}=\\mathbf{w}*\\mathbf{X}+\\mathbf{b}$$\n"]},{"cell_type":"markdown","metadata":{},"source":["In convolution, the parameter \u003cb\u003ew\u003c/b\u003e is called a kernel. You can perform convolution on images where you let the variable image denote the variable X and w denote the parameter.\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003cimg src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%206/6.1.1xw.png\" width=\"500,\" align=\"center\"\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["Create a two-dimensional convolution object by using the constructor Conv2d, the parameter \u003ccode\u003ein_channels\u003c/code\u003e and \u003ccode\u003eout_channels\u003c/code\u003e will be used for this section, and the parameter kernel_size will be three.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["conv = nn.Conv2d(in_channels=1, out_channels=1,kernel_size=3)\n","conv"]},{"cell_type":"markdown","metadata":{},"source":["Because the parameters in \u003ccode\u003enn.Conv2d\u003c/code\u003e are randomly initialized and learned through training, give them some values.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["conv.state_dict()['weight'][0][0]=torch.tensor([[1.0,0,-1.0],[2.0,0,-2.0],[1.0,0.0,-1.0]])\n","conv.state_dict()['bias'][0]=0.0\n","conv.state_dict()"]},{"cell_type":"markdown","metadata":{},"source":["Create a dummy tensor to represent an image. The shape of the image is (1,1,5,5) where:\n","\n","(number of inputs, number of channels, number of rows, number of columns ) \n","\n","Set the third column to 1:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image=torch.zeros(1,1,5,5)\n","image[0,0,:,2]=1\n","image"]},{"cell_type":"markdown","metadata":{},"source":["Call the object \u003ccode\u003econv\u003c/code\u003e on the tensor \u003ccode\u003eimage\u003c/code\u003e as an input to perform the convolution and assign the result to the tensor \u003ccode\u003ez\u003c/code\u003e. \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["z=conv(image)\n","z"]},{"cell_type":"markdown","metadata":{},"source":["The following animation illustrates the process, the kernel performs at the element-level multiplication on every element in the image in the corresponding region. The values are then added together. The kernel is then shifted and the process is repeated. \n"]},{"cell_type":"markdown","metadata":{},"source":["\u003cimg src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%206/6.1.1convltuon.gif\" width=\"500,\" align=\"center\"\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","\u003ca id=\"ref1\"\u003e\u003c/a\u003e\n","\u003ch2 align=center\u003eDetermining  the Size of the Output\u003c/h2\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["The size of the output is an important parameter. In this lab, you will assume square images. For rectangular images, the same formula can be used in for each dimension independently.  \n","\n","Let M be the size of the input and K be the size of the kernel. The size of the output is given by the following formula:\n"]},{"cell_type":"markdown","metadata":{},"source":["$$M_{new}=M-K+1$$\n"]},{"cell_type":"markdown","metadata":{},"source":["Create a kernel of size 2:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["K=2\n","conv1 = nn.Conv2d(in_channels=1, out_channels=1,kernel_size=K)\n","conv1.state_dict()['weight'][0][0]=torch.tensor([[1.0,1.0],[1.0,1.0]])\n","conv1.state_dict()['bias'][0]=0.0\n","conv1.state_dict()\n","conv1"]},{"cell_type":"markdown","metadata":{},"source":["Create an image of size 2:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["M=4\n","image1=torch.ones(1,1,M,M)"]},{"cell_type":"markdown","metadata":{},"source":["\u003cimg src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%206/6.1.1kernal2.png\" width=\"500,\" align=\"center\"\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["The following equation provides the output:\n"]},{"cell_type":"markdown","metadata":{},"source":["$$M_{new}=M-K+1$$\n","$$M_{new}=4-2+1$$\n","$$M_{new}=3$$\n"]},{"cell_type":"markdown","metadata":{},"source":["The following animation illustrates the process: The first iteration of the kernel overlay of the images produces one output. As the kernel is of size K, there are M-K  elements for the kernel to move in the horizontal direction. The same logic applies to the vertical direction.  \n"]},{"cell_type":"markdown","metadata":{},"source":["\u003cimg src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%206/6.1.1outsize.gif\" width=\"500,\" align=\"center\"\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["Perform the convolution and verify the size is correct:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["z1=conv1(image1)\n","print(\"z1:\",z1)\n","print(\"shape:\",z1.shape[2:4])"]},{"cell_type":"markdown","metadata":{},"source":["\u003ca id=\"ref2\"\u003e\u003c/a\u003e\n","\u003ch2 align=center\u003eStride parameter\u003c/h2\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["The parameter stride changes the number of shifts the kernel moves per iteration. As a result, the output size also changes and is given by the following formula:\n"]},{"cell_type":"markdown","metadata":{},"source":["$$M_{new}=\\dfrac{M-K}{stride}+1$$\n"]},{"cell_type":"markdown","metadata":{},"source":["Create a convolution object with a stride of 2:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["conv3 = nn.Conv2d(in_channels=1, out_channels=1,kernel_size=2,stride=2)\n","\n","conv3.state_dict()['weight'][0][0]=torch.tensor([[1.0,1.0],[1.0,1.0]])\n","conv3.state_dict()['bias'][0]=0.0\n","conv3.state_dict()"]},{"cell_type":"markdown","metadata":{},"source":["For an image with a size of 4, calculate the output size:\n"]},{"cell_type":"markdown","metadata":{},"source":["$$M_{new}=\\dfrac{M-K}{stride}+1$$\n","$$M_{new}=\\dfrac{4-2}{2}+1$$\n","$$M_{new}=2$$\n"]},{"cell_type":"markdown","metadata":{},"source":["The following animation illustrates the process: The first iteration of the kernel overlay of the images produces one output. Because the kernel is of size K, there are M-K=2 elements. The stride is 2 because it will move 2 elements at a time. As a result, you divide M-K by the stride value 2:\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003cimg src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%206/6.1.1stride2.gif\" width=\"500,\" align=\"center\"\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["Perform the convolution and verify the size is correct: \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["z3=conv3(image1)\n","\n","print(\"z3:\",z3)\n","print(\"shape:\",z3.shape[2:4])"]},{"cell_type":"markdown","metadata":{},"source":["\u003ca id='ref3'\u003e\u003c/a\u003e\n","\u003ch2 align=center\u003eZero Padding \u003c/h2\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["As you apply successive convolutions, the image will shrink. You can apply zero padding to keep the image at a reasonable size, which also holds information at the borders.\n"]},{"cell_type":"markdown","metadata":{},"source":["In addition, you might not get integer values for the size of the kernel. Consider the following image:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image1"]},{"cell_type":"markdown","metadata":{},"source":["Try performing convolutions with the \u003ccode\u003ekernel_size=2\u003c/code\u003e and a \u003ccode\u003estride=3\u003c/code\u003e. Use these values:\n","\n","$$M_{new}=\\dfrac{M-K}{stride}+1$$\n","$$M_{new}=\\dfrac{4-2}{3}+1$$\n","$$M_{new}=1.666$$\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["conv4 = nn.Conv2d(in_channels=1, out_channels=1,kernel_size=2,stride=3)\n","conv4.state_dict()['weight'][0][0]=torch.tensor([[1.0,1.0],[1.0,1.0]])\n","conv4.state_dict()['bias'][0]=0.0\n","conv4.state_dict()\n","z4=conv4(image1)\n","print(\"z4:\",z4)\n","print(\"z4:\",z4.shape[2:4])"]},{"cell_type":"markdown","metadata":{},"source":["You can add rows and columns of zeros around the image. This is called padding. In the constructor \u003ccode\u003eConv2d\u003c/code\u003e, you specify the number of rows or columns of zeros that you want to add with the parameter padding. \n","\n","For a square image, you merely pad an extra column of zeros to the first column and the last column. Repeat the process for the rows. As a result, for a square image, the width and height is the original size plus 2 x the number of padding elements specified. You can then determine the size of the output after subsequent operations accordingly as shown in the following equation where you determine the size of an image after padding and then applying a convolutions kernel of size K.\n"]},{"cell_type":"markdown","metadata":{},"source":["$$M'=M+2 \\times padding$$\n","$$M_{new}=M'-K+1$$\n"]},{"cell_type":"markdown","metadata":{},"source":["Consider the following example:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["conv5 = nn.Conv2d(in_channels=1, out_channels=1,kernel_size=2,stride=3,padding=1)\n","\n","conv5.state_dict()['weight'][0][0]=torch.tensor([[1.0,1.0],[1.0,1.0]])\n","conv5.state_dict()['bias'][0]=0.0\n","conv5.state_dict()\n","z5=conv5(image1)\n","print(\"z5:\",z5)\n","print(\"z5:\",z4.shape[2:4])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["The process is summarized in the following  animation: \n"]},{"cell_type":"markdown","metadata":{},"source":["\u003cimg src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%206/6.1.1zeropad.gif\" width=\"500,\" align=\"center\"\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ca id='ref4'\u003e\u003c/a\u003e\n","\u003ch2 align=center\u003ePractice Question \u003c/h2\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":[" A kernel of zeros with a kernel size=3  is applied to the following image: \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Image=torch.randn((1,1,4,4))\n","Image"]},{"cell_type":"markdown","metadata":{},"source":["Question: Without using the function, determine what the outputs values are as each element:\n"]},{"cell_type":"markdown","metadata":{},"source":["Double-click __here__ for the solution.\n","\n","\u003c!-- Your answer is below:\n","As each element of the kernel is zero, and for every  output, the image is multiplied  by the  kernel, the result is always zero \n","\n","--\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["Question: Use the following convolution object to perform convolution on the tensor   \u003ccode\u003eImage\u003c/code\u003e:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["conv = nn.Conv2d(in_channels=1, out_channels=1,kernel_size=3)\n","conv.state_dict()['weight'][0][0]=torch.tensor([[0,0,0],[0,0,0],[0,0.0,0]])\n","conv.state_dict()['bias'][0]=0.0"]},{"cell_type":"markdown","metadata":{},"source":["Double-click __here__ for the solution.\n","\u003c!-- Your answer is below:\n","conv(Image)\n","--\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["Question: You have an image of size 4. The parameters are as follows  kernel_size=2,stride=2. What is the size of the output?\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["Double-click __here__ for the solution.\n","\n","\u003c!-- Your answer is below:\n","(M-K)/stride +1\n","(4-2)/2 +1\n","2\n","--\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","\u003ca href=\"https://dataplatform.cloud.ibm.com/registration/stepone?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0110ENSkillsNetwork952-2022-01-01\u0026context=cpdaas\u0026apps=data_science_experience%2Cwatson_machine_learning\"\u003e\u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork/Template/module%201/images/Watson_Studio.png\"\u003e\u003c/a\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["### About the Authors:  \n","[Joseph Santarcangelo](https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0110ENSkillsNetwork952-2022-01-01) has a PhD in Electrical Engineering. His research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. \n","\n","Other contributors: [Michelle Carey](https://www.linkedin.com/in/michelleccarey/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0110ENSkillsNetwork952-2022-01-01), [Mavis Zhou](https://www.linkedin.com/in/jiahui-mavis-zhou-a4537814a/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0110ENSkillsNetwork952-2022-01-01) \n"]},{"cell_type":"markdown","metadata":{},"source":["\n","## Change Log\n","\n","|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2020-09-23  | 2.0  | Srishti  |  Migrated Lab to Markdown and added to course repo in GitLab |\n","\n","\n","\n","\u003chr\u003e\n","\n","## \u003ch3 align=\"center\"\u003e © IBM Corporation 2020. All rights reserved. \u003ch3/\u003e\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":2}