{"cells":[{"cell_type":"markdown","metadata":{},"source":["\u003cp style=\"text-align:center\"\u003e\n","    \u003ca href=\"https://skills.network/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0110ENSkillsNetwork952-2022-01-01\" target=\"_blank\"\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  /\u003e\n","    \u003c/a\u003e\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch1\u003eNeural Networks with Momentum\u003c/h1\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","\u003ch3\u003eObjective for this Notebook\u003ch3\u003e    \n","\u003ch5\u003e 1. Train Different Neural Networks Model different values for the Momentum Parameter.\u003c/h5\u003e\n","\u003ch5\u003e 2. Compare Results of Different Momentum Terms. \u003c/h5\u003e     \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2\u003eTable of Contents\u003c/h2\u003e\n","\u003cp\u003eIn this lab, you will see how different values for the momentum parameters affect the convergence rate of a neural network.\u003c/p\u003e\n","\n","\u003cul\u003e\n","\u003cli\u003e\u003ca href=\"#Model\"\u003eNeural Network Module and Function for Training\u003c/a\u003e\u003c/li\u003e\n","\u003cli\u003e\u003ca href=\"#Train\"\u003eTrain Different Neural Networks Model different values for the Momentum Parameter\u003c/a\u003e\u003c/li\u003e\n","\u003cli\u003e\u003ca href=\"#Result\"\u003eCompare Results of Different Momentum Terms\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\u003cp\u003eEstimated Time Needed: \u003cstrong\u003e25 min\u003c/strong\u003e\u003c/p\u003e\n","\n","\u003chr\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2\u003ePreparation\u003c/h2\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["We'll need the following libraries:  \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import the libraries for this lab\n","\n","import matplotlib.pyplot as plt \n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from matplotlib.colors import ListedColormap\n","from torch.utils.data import Dataset, DataLoader\n","\n","torch.manual_seed(1)\n","np.random.seed(1)"]},{"cell_type":"markdown","metadata":{},"source":["Functions used to plot:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define a function for plot the decision region\n","\n","def plot_decision_regions_3class(model, data_set):\n","    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA','#00AAFF'])\n","    cmap_bold = ListedColormap(['#FF0000', '#00FF00','#00AAFF'])\n","    X=data_set.x.numpy()\n","    y=data_set.y.numpy()\n","    h = .02\n","    x_min, x_max = X[:, 0].min() - 0.1 , X[:, 0].max() + 0.1 \n","    y_min, y_max = X[:, 1].min() - 0.1 , X[:, 1].max() + 0.1 \n","    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n","    XX=torch.torch.Tensor(np.c_[xx.ravel(), yy.ravel()])\n","    _,yhat=torch.max(model(XX),1)\n","    yhat=yhat.numpy().reshape(xx.shape)\n","    plt.pcolormesh(xx, yy, yhat, cmap=cmap_light)\n","    plt.plot(X[y[:]==0,0], X[y[:]==0,1], 'ro', label='y=0')\n","    plt.plot(X[y[:]==1,0], X[y[:]==1,1], 'go', label='y=1')\n","    plt.plot(X[y[:]==2,0], X[y[:]==2,1], 'o', label='y=2')\n","    plt.title(\"decision region\")\n","    plt.legend()"]},{"cell_type":"markdown","metadata":{},"source":["Create the dataset class \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create the dataset class\n","\n","class Data(Dataset):\n","    \n","    #  modified from: http://cs231n.github.io/neural-networks-case-study/\n","    # Constructor\n","    def __init__(self, K=3, N=500):\n","        D = 2\n","        X = np.zeros((N * K, D)) # data matrix (each row = single example)\n","        y = np.zeros(N * K, dtype='uint8') # class labels\n","        for j in range(K):\n","          ix = range(N * j, N * (j + 1))\n","          r = np.linspace(0.0, 1, N) # radius\n","          t = np.linspace(j * 4, (j + 1) * 4, N) + np.random.randn(N) * 0.2 # theta\n","          X[ix] = np.c_[r * np.sin(t), r * np.cos(t)]\n","          y[ix] = j\n","    \n","        self.y = torch.from_numpy(y).type(torch.LongTensor)\n","        self.x = torch.from_numpy(X).type(torch.FloatTensor)\n","        self.len = y.shape[0]\n","            \n","    # Getter\n","    def __getitem__(self, index):    \n","        return self.x[index], self.y[index]\n","    \n","    # Get Length\n","    def __len__(self):\n","        return self.len\n","    \n","    # Plot the diagram\n","    def plot_data(self):\n","        plt.plot(self.x[self.y[:] == 0, 0].numpy(), self.x[self.y[:] == 0, 1].numpy(), 'o', label=\"y=0\")\n","        plt.plot(self.x[self.y[:] == 1, 0].numpy(), self.x[self.y[:] == 1, 1].numpy(), 'ro', label=\"y=1\")\n","        plt.plot(self.x[self.y[:] == 2, 0].numpy(),self.x[self.y[:] == 2, 1].numpy(), 'go',label=\"y=2\")\n","        plt.legend()"]},{"cell_type":"markdown","metadata":{},"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2 id=\"Model\"\u003eNeural Network Module and Function for Training\u003c/h2\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["Create Neural Network Module using \u003ccode\u003eModuleList()\u003c/code\u003e\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create dataset object\n","\n","class Net(nn.Module):\n","    \n","    # Constructor\n","    def __init__(self, Layers):\n","        super(Net, self).__init__()\n","        self.hidden = nn.ModuleList()\n","        for input_size, output_size in zip(Layers, Layers[1:]):\n","            self.hidden.append(nn.Linear(input_size, output_size))\n","    \n","    # Prediction\n","    def forward(self, activation):\n","        L = len(self.hidden)\n","        for (l, linear_transform) in zip(range(L), self.hidden):\n","            if l \u003c L - 1:\n","                activation = F.relu(linear_transform(activation))    \n","            else:\n","                activation = linear_transform(activation)\n","        return activation"]},{"cell_type":"markdown","metadata":{},"source":["Create the function for training the model.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the function for training the model\n","\n","def train(data_set, model, criterion, train_loader, optimizer, epochs=100):\n","    LOSS = []\n","    ACC = []\n","    for epoch in range(epochs):\n","        for x, y in train_loader:\n","            optimizer.zero_grad()\n","            yhat = model(x)\n","            loss = criterion(yhat, y)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","        LOSS.append(loss.item())\n","        ACC.append(accuracy(model,data_set))\n","        \n","    results ={\"Loss\":LOSS, \"Accuracy\":ACC}\n","    fig, ax1 = plt.subplots()\n","    color = 'tab:red'\n","    ax1.plot(LOSS,color=color)\n","    ax1.set_xlabel('epoch', color=color)\n","    ax1.set_ylabel('total loss', color=color)\n","    ax1.tick_params(axis = 'y', color=color)\n","    \n","    ax2 = ax1.twinx()  \n","    color = 'tab:blue'\n","    ax2.set_ylabel('accuracy', color=color)  # we already handled the x-label with ax1\n","    ax2.plot(ACC, color=color)\n","    ax2.tick_params(axis='y', color=color)\n","    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n","    \n","    plt.show()\n","    return results"]},{"cell_type":"markdown","metadata":{},"source":["Define a function used to calculate accuracy.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define a function for calculating accuracy\n","\n","def accuracy(model, data_set):\n","    _, yhat = torch.max(model(data_set.x), 1)\n","    return (yhat == data_set.y).numpy().mean()"]},{"cell_type":"markdown","metadata":{},"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2 id=\"Train\"\u003eTrain Different Networks Model different values for the Momentum Parameter\u003c/h2\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["Crate a dataset object using \u003ccode\u003eData\u003c/code\u003e\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create the dataset and plot it\n","\n","data_set = Data()\n","data_set.plot_data()\n","data_set.y = data_set.y.view(-1)"]},{"cell_type":"markdown","metadata":{},"source":["Dictionary to contain different cost and  accuracy values for each epoch  for different values of the momentum parameter.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize a dictionary to contain the cost and accuracy\n","\n","Results = {\"momentum 0\": {\"Loss\": 0, \"Accuracy:\": 0}, \"momentum 0.1\": {\"Loss\": 0, \"Accuracy:\": 0}}"]},{"cell_type":"markdown","metadata":{},"source":["Create a  network to classify three classes with 1 hidden layer with 50 neurons and a momentum value of zero.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train a model with 1 hidden layer and 50 neurons\n","\n","Layers = [2, 50, 3]\n","model = Net(Layers)\n","learning_rate = 0.10\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","train_loader = DataLoader(dataset=data_set, batch_size=20)\n","criterion = nn.CrossEntropyLoss()\n","Results[\"momentum 0\"] = train(data_set, model, criterion, train_loader, optimizer, epochs=100)\n","plot_decision_regions_3class(model, data_set)"]},{"cell_type":"markdown","metadata":{},"source":["Create a network to classify three classes with 1 hidden layer with 50 neurons and a momentum value of 0.1.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train a model with 1 hidden layer and 50 neurons with 0.1 momentum\n","\n","Layers = [2, 50, 3]\n","model = Net(Layers)\n","learning_rate = 0.10\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.1)\n","train_loader = DataLoader(dataset=data_set, batch_size=20)\n","criterion = nn.CrossEntropyLoss()\n","Results[\"momentum 0.1\"] = train(data_set, model, criterion, train_loader, optimizer, epochs=100)\n","plot_decision_regions_3class(model, data_set)"]},{"cell_type":"markdown","metadata":{},"source":["\n","Create a network to classify three classes with 1 hidden layer with 50 neurons and a momentum value of 0.2.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train a model with 1 hidden layer and 50 neurons with 0.2 momentum\n","\n","Layers = [2, 50, 3]\n","model = Net(Layers)\n","learning_rate = 0.10\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.2)\n","train_loader = DataLoader(dataset=data_set, batch_size=20)\n","criterion = nn.CrossEntropyLoss()\n","Results[\"momentum 0.2\"] = train(data_set, model, criterion, train_loader, optimizer, epochs=100)\n","plot_decision_regions_3class(model, data_set)"]},{"cell_type":"markdown","metadata":{},"source":["Create a network to classify three classes with 1 hidden layer with 50 neurons and a momentum value of 0.4.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train a model with 1 hidden layer and 50 neurons with 0.4 momentum\n","\n","Layers = [2, 50, 3]\n","model = Net(Layers)\n","learning_rate = 0.10\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.4)\n","train_loader = DataLoader(dataset=data_set, batch_size=20)\n","criterion = nn.CrossEntropyLoss()\n","Results[\"momentum 0.4\"] = train(data_set, model, criterion, train_loader, optimizer, epochs=100)\n","plot_decision_regions_3class(model, data_set)"]},{"cell_type":"markdown","metadata":{},"source":["Create a network to classify three classes with 1 hidden layer with 50 neurons and a momentum value of 0.5.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train a model with 1 hidden layer and 50 neurons with 0.5 momentum\n","\n","Layers = [2, 50, 3]\n","model = Net(Layers)\n","learning_rate = 0.10\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.5)\n","train_loader = DataLoader(dataset=data_set, batch_size=20)\n","criterion = nn.CrossEntropyLoss()\n","Results[\"momentum 0.5\"] = train(data_set, model, criterion, train_loader, optimizer, epochs=100)\n","plot_decision_regions_3class(model,data_set)"]},{"cell_type":"markdown","metadata":{},"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2 id=\"Result\"\u003eCompare Results of Different Momentum Terms\u003c/h2\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["The plot below compares results of different momentum terms. We see that in general. The Cost decreases proportionally to the momentum term, but larger momentum terms lead to larger oscillations. While the momentum term decreases faster, it seems that a momentum term of 0.2 reaches the smallest value for the cost. \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the Loss result for each term\n","\n","for key, value in Results.items():\n","    plt.plot(value['Loss'],label=key)\n","    plt.legend()\n","    plt.xlabel('epoch')\n","    plt.ylabel('Total Loss or Cost')"]},{"cell_type":"markdown","metadata":{},"source":["The  accuracy seems to be proportional to the momentum term.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the Accuracy result for each term\n","\n","for key, value in Results.items():\n","    plt.plot(value['Accuracy'],label=key)\n","    plt.legend()\n","    plt.xlabel('epoch')\n","    plt.ylabel('Accuracy')"]},{"cell_type":"markdown","metadata":{},"source":["\n","\u003ca href=\"https://dataplatform.cloud.ibm.com/registration/stepone?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0110ENSkillsNetwork952-2022-01-01\u0026context=cpdaas\u0026apps=data_science_experience%2Cwatson_machine_learning\"\u003e\u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork/Template/module%201/images/Watson_Studio.png\"\u003e\u003c/a\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2\u003eAbout the Authors:\u003c/h2\u003e \n","\n","\u003ca href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0110ENSkillsNetwork952-2022-01-01\"\u003eJoseph Santarcangelo\u003c/a\u003e has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. \n"]},{"cell_type":"markdown","metadata":{},"source":["Other contributors: \u003ca href=\"https://www.linkedin.com/in/michelleccarey/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0110ENSkillsNetwork952-2022-01-01\"\u003eMichelle Carey\u003c/a\u003e, \u003ca href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\"\u003eMavis Zhou\u003c/a\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","## Change Log\n","\n","|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2020-09-23  | 2.0  | Srishti  |  Migrated Lab to Markdown and added to course repo in GitLab |\n","\n","\n","\n","\u003chr\u003e\n","\n","## \u003ch3 align=\"center\"\u003e © IBM Corporation 2020. All rights reserved. \u003ch3/\u003e\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":2}