{"cells":[{"cell_type":"markdown","id":"cc45a8d9-d6c7-4471-bff9-6ca8d57ecda0","metadata":{},"outputs":[],"source":["\u003cp style=\"text-align:center\"\u003e\n","    \u003ca href=\"https://skills.network/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0110ENSkillsNetwork952-2022-01-01\" target=\"_blank\"\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  /\u003e\n","    \u003c/a\u003e\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"2893d215-51d5-4b97-8cf3-244aec4ce9df","metadata":{},"outputs":[],"source":["\u003ch1\u003eTest Uniform, Default and He Initialization on MNIST Dataset with Relu Activation\u003c/h1\u003e\n"]},{"cell_type":"markdown","id":"5000edf7-da2a-4410-b829-f7dab55c90f4","metadata":{},"outputs":[],"source":["\n","\u003ch3\u003eObjective for this Notebook\u003ch3\u003e    \n","\u003ch5\u003e 1. Learn how to Define Several Neural Network, Criterion function, Optimizer.\u003c/h5\u003e\n","\u003ch5\u003e 2. Test Uniform, Default and He Initialization \u003c/h5\u003e   \n","\n"]},{"cell_type":"markdown","id":"c6adb9fb-bf69-4b69-83aa-95e1a63e4a61","metadata":{},"outputs":[],"source":["\u003ch2\u003eTable of Contents\u003c/h2\u003e\n","\u003cp\u003eIn this lab, you will test the Uniform Initialization, Default Initialization and He Initialization on the MNIST dataset with Relu Activation\u003c/p\u003e\n","\n","\u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"#Model\"\u003eNeural Network Module and Training Function\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Makeup_Data\"\u003eMake Some Data\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Cost\"\u003eDefine Several Neural Network, Criterion function, Optimizer\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Train\"\u003eTest Uniform, Default and He Initialization\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Result\"\u003eAnalyze Results\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\u003cp\u003eEstimated Time Needed: \u003cstrong\u003e25 min\u003c/strong\u003e\u003c/p\u003e\n","\n","\u003chr\u003e\n"]},{"cell_type":"markdown","id":"c2b20171-d1ab-4894-ad25-1326340572f4","metadata":{},"outputs":[],"source":["\u003ch2\u003ePreparation\u003c/h2\u003e\n"]},{"cell_type":"markdown","id":"ed061313-50d4-4c76-a9d2-1a7e53063db5","metadata":{},"outputs":[],"source":["We'll need the following libraries:  \n"]},{"cell_type":"code","id":"1690c25b-7bf2-40c5-9eea-ac74a274fcde","metadata":{},"outputs":[],"source":["# Import the libraries we need to use in this lab\n\n# Using the following line code to install the torchvision library\n# !mamba install -y torchvision\n\nimport torch \nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dsets\nimport torch.nn.functional as F\nimport matplotlib.pylab as plt\nimport numpy as np\n\ntorch.manual_seed(0)"]},{"cell_type":"markdown","id":"7ca56cb2-fb84-4c18-af56-a0506796f127","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"16a6c838-57e9-4231-b640-5d69b8e50f45","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Model\"\u003eNeural Network Module and Training Function\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"f2164b31-d619-453f-b8a6-a4b83cb4d67e","metadata":{},"outputs":[],"source":["Define the neural network module or class with He Initialization\n"]},{"cell_type":"code","id":"caf115c2-cbab-4477-b4f2-1055108c3123","metadata":{},"outputs":[],"source":["# Define the class for neural network model with He Initialization\n\nclass Net_He(nn.Module):\n    \n    # Constructor\n    def __init__(self, Layers):\n        super(Net_He, self).__init__()\n        self.hidden = nn.ModuleList()\n\n        for input_size, output_size in zip(Layers, Layers[1:]):\n            linear = nn.Linear(input_size, output_size)\n            torch.nn.init.kaiming_uniform_(linear.weight, nonlinearity='relu')\n            self.hidden.append(linear)\n\n    # Prediction\n    def forward(self, x):\n        L = len(self.hidden)\n        for (l, linear_transform) in zip(range(L), self.hidden):\n            if l \u003c L - 1:\n                x = F.relu(linear_transform(x))\n            else:\n                x = linear_transform(x)\n        return x"]},{"cell_type":"markdown","id":"2f57e411-028f-4c8b-b32e-38613edbedb7","metadata":{},"outputs":[],"source":["Define the class or neural network with Uniform Initialization\n"]},{"cell_type":"code","id":"6ce18c40-1d2e-416c-ad0c-59d7c11551e7","metadata":{},"outputs":[],"source":["# Define the class for neural network model with Uniform Initialization\n\nclass Net_Uniform(nn.Module):\n    \n    # Constructor\n    def __init__(self, Layers):\n        super(Net_Uniform, self).__init__()\n        self.hidden = nn.ModuleList()\n\n        for input_size, output_size in zip(Layers, Layers[1:]):\n            linear = nn.Linear(input_size,output_size)\n            linear.weight.data.uniform_(0, 1)\n            self.hidden.append(linear)\n    \n    # Prediction\n    def forward(self, x):\n        L = len(self.hidden)\n        for (l, linear_transform) in zip(range(L), self.hidden):\n            if l \u003c L - 1:\n                x = F.relu(linear_transform(x))\n            else:\n                x = linear_transform(x)\n                \n        return x"]},{"cell_type":"markdown","id":"92873e94-2eb8-4bcc-913d-29dd20ab82b2","metadata":{},"outputs":[],"source":["Class or Neural Network with PyTorch Default Initialization\n"]},{"cell_type":"code","id":"e052d988-31b2-49d6-849a-b5d8a4096d7a","metadata":{},"outputs":[],"source":["# Define the class for neural network model with PyTorch Default Initialization\n\nclass Net(nn.Module):\n    \n    # Constructor\n    def __init__(self, Layers):\n        super(Net, self).__init__()\n        self.hidden = nn.ModuleList()\n\n        for input_size, output_size in zip(Layers, Layers[1:]):\n            linear = nn.Linear(input_size, output_size)\n            self.hidden.append(linear)\n        \n    def forward(self, x):\n        L=len(self.hidden)\n        for (l, linear_transform) in zip(range(L), self.hidden):\n            if l \u003c L - 1:\n                x = F.relu(linear_transform(x))\n            else:\n                x = linear_transform(x)\n                \n        return x"]},{"cell_type":"markdown","id":"be8f117c-598b-4633-9747-4fda620b1260","metadata":{},"outputs":[],"source":["Define a function to train the model, in this case the function returns a Python dictionary to store the training loss and accuracy on the validation data \n"]},{"cell_type":"code","id":"4d70068e-1ade-478f-8015-3f09ea4f9c8f","metadata":{},"outputs":[],"source":["# Define function to  train model\n\ndef train(model, criterion, train_loader, validation_loader, optimizer, epochs = 100):\n    i = 0\n    loss_accuracy = {'training_loss': [], 'validation_accuracy': []}  \n    \n    #n_epochs\n    for epoch in range(epochs):\n        for i, (x, y) in enumerate(train_loader):\n            optimizer.zero_grad()\n            z = model(x.view(-1, 28 * 28))\n            loss = criterion(z, y)\n            loss.backward()\n            optimizer.step()\n            loss_accuracy['training_loss'].append(loss.data.item())\n        \n        correct = 0\n        for x, y in validation_loader:\n            yhat = model(x.view(-1, 28 * 28))\n            _, label = torch.max(yhat, 1)\n            correct += (label == y).sum().item()\n        accuracy = 100 * (correct / len(validation_dataset))\n        loss_accuracy['validation_accuracy'].append(accuracy)\n    \n    return loss_accuracy"]},{"cell_type":"markdown","id":"d1c9722f-d350-4975-86c4-32662c3d06bc","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"66f3a5fe-e21d-43c3-aad9-055db35b0cbb","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Makeup_Data\"\u003eMake some Data\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"a7b252c2-687c-4927-9f49-ee5484f3d91e","metadata":{},"outputs":[],"source":["Load the training dataset by setting the parameters \u003ccode\u003etrain \u003c/code\u003e to \u003ccode\u003eTrue\u003c/code\u003e and convert it to a tensor  by placing a transform object int the argument \u003ccode\u003etransform\u003c/code\u003e\n"]},{"cell_type":"code","id":"bdd5c5c4-fd58-4b2a-9d43-5dd021b569ee","metadata":{},"outputs":[],"source":["# Create the training dataset\n\ntrain_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())"]},{"cell_type":"markdown","id":"1d561877-56a8-4a9c-9724-9d8cb9a95d42","metadata":{},"outputs":[],"source":["Load the testing dataset by setting the parameters train  \u003ccode\u003eFalse\u003c/code\u003e and convert it to a tensor  by placing a transform object int the argument \u003ccode\u003etransform\u003c/code\u003e\n"]},{"cell_type":"code","id":"7d083ed5-e256-444f-9bec-82b07b909fd9","metadata":{},"outputs":[],"source":["# Create the validation dataset\n\nvalidation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"]},{"cell_type":"markdown","id":"49bac2f4-b4c6-4850-a36f-3b648959d9df","metadata":{},"outputs":[],"source":["Create the training-data loader and the validation-data loader object \n"]},{"cell_type":"code","id":"4567e342-d5ba-4284-a847-0e93b9156a40","metadata":{},"outputs":[],"source":["# Create the data loader for training and validation\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True)\nvalidation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000, shuffle=False)"]},{"cell_type":"markdown","id":"9eb0c037-2357-469a-975c-1252ad19e22a","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"128855f3-827a-455c-9a44-f3a953a06cab","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Cost\"\u003eDefine Neural Network, Criterion function, Optimizer and Train the Model\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"930b32ed-02ed-4803-8d3b-93618372751c","metadata":{},"outputs":[],"source":["Create the criterion function  \n"]},{"cell_type":"code","id":"e1ec429d-2437-4f0d-958c-1505b5cf1022","metadata":{},"outputs":[],"source":["# Create the criterion function\n\ncriterion = nn.CrossEntropyLoss()"]},{"cell_type":"markdown","id":"a0ef18e5-05fd-426c-87e1-234b23e3cfc3","metadata":{},"outputs":[],"source":["Create a list that contains layer size \n"]},{"cell_type":"code","id":"ceddc4c9-ae2a-49a2-ad21-c4295870407a","metadata":{},"outputs":[],"source":["# Create the parameters\n\ninput_dim = 28 * 28\noutput_dim = 10\nlayers = [input_dim, 100, 200, 100, output_dim]"]},{"cell_type":"markdown","id":"67a84ead-dda4-492b-8f28-b10c263985dc","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"bd86ab06-e9fb-460e-850c-5bc8287e2a54","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Train\"\u003eTest PyTorch Default Initialization, Xavier Initialization and Uniform Initialization\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"de8eca2e-1dcf-4736-b839-82c161179a0e","metadata":{},"outputs":[],"source":["Train the network using PyTorch Default Initialization\n"]},{"cell_type":"code","id":"69a85ea5-138b-4ad4-8c9b-7d6cef8db7af","metadata":{},"outputs":[],"source":["# Train the model with the default initialization\n\nmodel = Net(layers)\nlearning_rate = 0.01\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\ntraining_results = train(model, criterion, train_loader,validation_loader, optimizer, epochs=30)"]},{"cell_type":"markdown","id":"f5d8cb53-b462-4576-ba3c-94d08566a282","metadata":{},"outputs":[],"source":["Train the network using He Initialization function\n"]},{"cell_type":"code","id":"4dd0b180-f5c1-4cb9-be98-3530417bd183","metadata":{},"outputs":[],"source":["# Train the model with the He initialization\n\nmodel_He = Net_He(layers)\noptimizer = torch.optim.SGD(model_He.parameters(), lr=learning_rate)\ntraining_results_He = train(model_He, criterion, train_loader, validation_loader, optimizer, epochs=30)"]},{"cell_type":"markdown","id":"9126f180-d092-416e-9177-b21904dd8400","metadata":{},"outputs":[],"source":["Train the network using Uniform Initialization function\n"]},{"cell_type":"code","id":"5e166e29-2e8a-4601-97f8-9cb55a7d20ad","metadata":{},"outputs":[],"source":["# Train the model with the Uniform initialization\n\nmodel_Uniform = Net_Uniform(layers)\noptimizer = torch.optim.SGD(model_Uniform.parameters(), lr=learning_rate)\ntraining_results_Uniform = train(model_Uniform, criterion, train_loader, validation_loader, optimizer, epochs=30)"]},{"cell_type":"markdown","id":"bea7e077-05d4-4ee7-b116-e60ee5f989f2","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"cbdcc7df-0f86-486d-a382-827f20878228","metadata":{},"outputs":[],"source":["\u003ch2 id=\"Result\"\u003eAnalyze Results\u003c/h2\u003e \n"]},{"cell_type":"markdown","id":"ac8bfb50-6d42-473e-9dae-6c69bafb011c","metadata":{},"outputs":[],"source":["Compare the training loss for each activation \n"]},{"cell_type":"code","id":"ae811cea-1d9c-425c-a302-18fa09062a6c","metadata":{},"outputs":[],"source":["# Plot the loss\n\nplt.plot(training_results_He['training_loss'], label='He')\nplt.plot(training_results['training_loss'], label='Default')\nplt.plot(training_results_Uniform['training_loss'], label='Uniform')\nplt.ylabel('loss')\nplt.xlabel('iteration ') \nplt.title('training loss iterations')\nplt.legend()"]},{"cell_type":"markdown","id":"c28cc8d6-9559-403a-a1f4-3d012af62488","metadata":{},"outputs":[],"source":["Compare the validation loss for each model  \n"]},{"cell_type":"code","id":"9c19cd6a-c608-4f57-b0e2-8d09b25eddf9","metadata":{},"outputs":[],"source":["# Plot the accuracy\n\nplt.plot(training_results_He['validation_accuracy'], label='He')\nplt.plot(training_results['validation_accuracy'], label='Default')\nplt.plot(training_results_Uniform['validation_accuracy'], label='Uniform') \nplt.ylabel('validation accuracy')\nplt.xlabel('epochs ')   \nplt.legend()\nplt.show()"]},{"cell_type":"markdown","id":"25a1be1f-13ff-458b-8a49-5b5d7ae40a8d","metadata":{},"outputs":[],"source":["\n","\u003ca href=\"https://dataplatform.cloud.ibm.com/registration/stepone?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0110ENSkillsNetwork952-2022-01-01\u0026context=cpdaas\u0026apps=data_science_experience%2Cwatson_machine_learning\"\u003e\u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork/Template/module%201/images/Watson_Studio.png\"\u003e\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"5eb5106b-1066-4a3e-800e-34d05746b6a9","metadata":{},"outputs":[],"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","id":"9088fb83-3627-4ca4-b5ae-43f6dbb17c2a","metadata":{},"outputs":[],"source":["\u003ch2\u003eAbout the Authors:\u003c/h2\u003e \n","\n","\u003ca href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0110ENSkillsNetwork952-2022-01-01\"\u003eJoseph Santarcangelo\u003c/a\u003e has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. \n"]},{"cell_type":"markdown","id":"4be532b6-168b-4dfd-b7d0-033c8c987bb1","metadata":{},"outputs":[],"source":["Other contributors: \u003ca href=\"https://www.linkedin.com/in/michelleccarey/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0110ENSkillsNetwork952-2022-01-01\"\u003eMichelle Carey\u003c/a\u003e, \u003ca href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\"\u003eMavis Zhou\u003c/a\u003e\n"]},{"cell_type":"markdown","id":"f7b26e6d-97ef-49ff-a71f-478e98d6b74e","metadata":{},"outputs":[],"source":["\n","## Change Log\n","\n","|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2020-09-23  | 2.0  | Srishti  |  Migrated Lab to Markdown and added to course repo in GitLab |\n","\n","\n","\n","\u003chr\u003e\n","\n","## \u003ch3 align=\"center\"\u003e Â© IBM Corporation 2020. All rights reserved. \u003ch3/\u003e\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}