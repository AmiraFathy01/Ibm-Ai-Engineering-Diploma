{"cells":[{"cell_type":"markdown","metadata":{},"source":["\u003cp style=\"text-align:center\"\u003e\n","    \u003ca href=\"https://skills.network/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0110ENSkillsNetwork952-2022-01-01\" target=\"_blank\"\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  /\u003e\n","    \u003c/a\u003e\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch1\u003eTest Sigmoid, Tanh, and Relu Activations Functions on the MNIST Dataset\u003c/h1\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2\u003eObjective\u003c/h2\u003e\u003cul\u003e\u003cli\u003e How to apply different activation functions on the MNIST dataset.\u003c/li\u003e\u003c/ul\u003e \n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2\u003eTable of Contents\u003c/h2\u003e\n","\u003cp\u003eIn this lab, you will test sigmoid, tanh, and relu activation functions on the MNIST dataset.\u003c/p\u003e\n","\n","\u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"#Model\"\u003eNeural Network Module and Training Function\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Makeup_Data\"\u003eMake Some Data\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Train\"\u003eDefine Several Neural Network, Criterion Function, and Optimizer\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Test\"\u003eTest Sigmoid, Tanh, and Relu\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Result\"\u003eAnalyze Results\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\u003cp\u003e\u003c/p\u003e\n","Estimated Time Needed: \u003cstrong\u003e25 min\u003c/strong\u003e\n","\u003c/div\u003e\n","\n","\u003chr\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2\u003ePreparation\u003c/h2\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["We'll need the following libraries\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Uncomment the following line to install the torchvision library\n","# !mamba install -y torchvision\n","\n","# Import the libraries we need for this lab\n","\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","\n","import matplotlib.pylab as plt\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2 id=\"Model\"\u003eNeural Network Module and Training Function\u003c/h2\u003e \n"]},{"cell_type":"markdown","metadata":{},"source":["Define the neural network module or class using the sigmoid activation function: \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Build the model with sigmoid function\n","\n","class Net(nn.Module):\n","    \n","    # Constructor\n","    def __init__(self, D_in, H, D_out):\n","        super(Net, self).__init__()\n","        self.linear1 = nn.Linear(D_in, H)\n","        self.linear2 = nn.Linear(H, D_out)\n","    \n","    # Prediction\n","    def forward(self, x):\n","        x = torch.sigmoid(self.linear1(x))  \n","        x = self.linear2(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["\n","Define the neural network module or class using the Tanh activation function:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Build the model with Tanh function\n","\n","class NetTanh(nn.Module):\n","\n","    # Constructor\n","    def __init__(self, D_in, H, D_out):\n","        super(NetTanh, self).__init__()\n","        self.linear1 = nn.Linear(D_in, H)\n","        self.linear2 = nn.Linear(H, D_out)\n","\n","    # Prediction\n","    def forward(self, x):\n","        x = torch.tanh(self.linear1(x))\n","        x = self.linear2(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["Define the neural network module or class using the Relu activation function:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Build the model with Relu function\n","\n","class NetRelu(nn.Module):\n","\n","    # Constructor\n","    def __init__(self, D_in, H, D_out):\n","        super(NetRelu, self).__init__()\n","        self.linear1 = nn.Linear(D_in, H)\n","        self.linear2 = nn.Linear(H, D_out)\n","\n","    # Prediction\n","    def forward(self, x):\n","        x = torch.relu(self.linear1(x))\n","        x = self.linear2(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["Define a function to train the model. In this case, the function returns a Python dictionary to store the training loss for each iteration  and accuracy on the validation data.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the function for training the model\n","\n","def train(model, criterion, train_loader, validation_loader, optimizer, epochs = 100):\n","    i = 0\n","    useful_stuff = {'training_loss':[], 'validation_accuracy':[]}  \n","\n","    for epoch in range(epochs):\n","        for i, (x, y) in enumerate(train_loader):\n","            optimizer.zero_grad()\n","            z = model(x.view(-1, 28 * 28))\n","            loss = criterion(z, y)\n","            loss.backward()\n","            optimizer.step()\n","            useful_stuff['training_loss'].append(loss.item())\n","\n","        correct = 0\n","        for x, y in validation_loader:\n","            z = model(x.view(-1, 28 * 28))\n","            _, label=torch.max(z, 1)\n","            correct += (label == y).sum().item()\n","        accuracy = 100 * (correct / len(validation_dataset))\n","        useful_stuff['validation_accuracy'].append(accuracy)\n","\n","    return useful_stuff"]},{"cell_type":"markdown","metadata":{},"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2 id=\"Makeup_Data\"\u003eMake Some Data\u003c/h2\u003e \n"]},{"cell_type":"markdown","metadata":{},"source":["Load the training dataset by setting the parameters \u003ccode\u003etrain\u003c/code\u003e to \u003ccode\u003eTrue\u003c/code\u003e and convert it to a tensor by placing a transform object in the argument \u003ccode\u003etransform\u003c/code\u003e.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create the training dataset\n","\n","train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())"]},{"cell_type":"markdown","metadata":{},"source":["Load the testing dataset by setting the parameter \u003ccode\u003etrain\u003c/code\u003e to \u003ccode\u003eFalse\u003c/code\u003e and convert it to a tensor by placing a transform object in the argument \u003ccode\u003etransform\u003c/code\u003e.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create the validation  dataset\n","\n","validation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"]},{"cell_type":"markdown","metadata":{},"source":["Create the criterion function:  \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create the criterion function\n","\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"markdown","metadata":{},"source":["Create the training-data loader and the validation-data loader object:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create the training data loader and validation data loader object\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True)\n","validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000, shuffle=False)"]},{"cell_type":"markdown","metadata":{},"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2 id=\"Train\"\u003eDefine the Neural Network, Criterion Function, Optimizer, and Train the Model\u003c/h2\u003e \n"]},{"cell_type":"markdown","metadata":{},"source":["Create the criterion function: \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create the criterion function\n","\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"markdown","metadata":{},"source":["Create the model with 100 hidden neurons:  \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create the model object\n","\n","input_dim = 28 * 28\n","hidden_dim = 100\n","output_dim = 10\n","\n","model = Net(input_dim, hidden_dim, output_dim)"]},{"cell_type":"markdown","metadata":{},"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2 id=\"Test\"\u003eTest Sigmoid, Tanh, and Relu\u003c/h2\u003e \n"]},{"cell_type":"markdown","metadata":{},"source":["Train the network by using the sigmoid activations function:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train a model with sigmoid function\n","\n","learning_rate = 0.01\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","training_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs=30)"]},{"cell_type":"markdown","metadata":{},"source":["Train the network by using the Tanh activations function:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train a model with Tanh function\n","\n","model_Tanh = NetTanh(input_dim, hidden_dim, output_dim)\n","optimizer = torch.optim.SGD(model_Tanh.parameters(), lr=learning_rate)\n","training_results_tanch = train(model_Tanh, criterion, train_loader, validation_loader, optimizer, epochs=30)"]},{"cell_type":"markdown","metadata":{},"source":["Train the network by using the Relu activations function:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train a model with Relu function\n","\n","modelRelu = NetRelu(input_dim, hidden_dim, output_dim)\n","optimizer = torch.optim.SGD(modelRelu.parameters(), lr=learning_rate)\n","training_results_relu = train(modelRelu, criterion, train_loader, validation_loader, optimizer, epochs=30)"]},{"cell_type":"markdown","metadata":{},"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2 id=\"Result\"\u003eAnalyze Results\u003c/h2\u003e \n"]},{"cell_type":"markdown","metadata":{},"source":["Compare the training loss for each activation: \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Compare the training loss\n","\n","plt.plot(training_results_tanch['training_loss'], label='tanh')\n","plt.plot(training_results['training_loss'], label='sigmoid')\n","plt.plot(training_results_relu['training_loss'], label='relu')\n","plt.ylabel('loss')\n","plt.title('training loss iterations')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Compare the validation loss for each model:  \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Compare the validation loss\n","\n","plt.plot(training_results_tanch['validation_accuracy'], label='tanh')\n","plt.plot(training_results['validation_accuracy'], label='sigmoid')\n","plt.plot(training_results_relu['validation_accuracy'], label='relu') \n","plt.ylabel('validation accuracy')\n","plt.xlabel('epochs ')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["\u003c!--Empty Space for separating topics--\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["## Which activation function performed best ?\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","\u003ca href=\"https://dataplatform.cloud.ibm.com/registration/stepone?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0110ENSkillsNetwork952-2022-01-01\u0026context=cpdaas\u0026apps=data_science_experience%2Cwatson_machine_learning\"\u003e\u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork/Template/module%201/images/Watson_Studio.png\"\u003e\u003c/a\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2\u003eAbout the Authors:\u003c/h2\u003e \n","\n","\u003ca href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0110ENSkillsNetwork952-2022-01-01\"\u003eJoseph Santarcangelo\u003c/a\u003e has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. \n"]},{"cell_type":"markdown","metadata":{},"source":["Other contributors: \u003ca href=\"https://www.linkedin.com/in/michelleccarey/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0110ENSkillsNetwork952-2022-01-01\"\u003eMichelle Carey\u003c/a\u003e, \u003ca href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\"\u003eMavis Zhou\u003c/a\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","## Change Log\n","\n","|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2020-09-23  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003chr\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","\n","\n","## \u003ch3 align=\"center\"\u003e © IBM Corporation 2020. All rights reserved. \u003ch3/\u003e\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}